
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>fibber.datasets.dataset_utils module &#8212; fibber 0.0.1.dev0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/dai-logo-white.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fibber.datasets.download_datasets module" href="fibber.datasets.download_datasets.html" />
    <link rel="prev" title="fibber.datasets package" href="fibber.datasets.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/dai-logo-white-200.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../readme.html">Fibber</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="fibber.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../contributing.html">Contributing</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../authors.html">Credits</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../history.html">History</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/sdv-dev/fibber" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="fibber.benchmark.html">fibber.benchmark package</a>
                </li>
            
          
            
  
                <li class="active">
                    <a href="fibber.datasets.html">fibber.datasets package</a>
                    <ul>
                    
                        <li class="active">
                            <a href="">fibber.datasets.dataset_utils module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.download_datasets.html">fibber.datasets.download_datasets module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.downloadable_datasets.html">fibber.datasets.downloadable_datasets module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_ag.html">fibber.datasets.preprocess_ag module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_imdb.html">fibber.datasets.preprocess_imdb module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_mnli.html">fibber.datasets.preprocess_mnli module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_mr.html">fibber.datasets.preprocess_mr module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_snli.html">fibber.datasets.preprocess_snli module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_utils.html">fibber.datasets.preprocess_utils module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.datasets.preprocess_yelp.html">fibber.datasets.preprocess_yelp module</a>
                        </li>
                    
                    </ul>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.metrics.html">fibber.metrics package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.paraphrase_strategies.html">fibber.paraphrase_strategies package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.resources.html">fibber.resources package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.download_utils.html">fibber.download_utils module</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.fibber.html">fibber.fibber module</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.log.html">fibber.log module</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-fibber.datasets.dataset_utils">
<span id="fibber-datasets-dataset-utils-module"></span><h1>fibber.datasets.dataset_utils module<a class="headerlink" href="#module-fibber.datasets.dataset_utils" title="Permalink to this headline">¶</a></h1>
<p>This module provides utility functions and classes to handle fibber’s datasets.</p>
<ul>
<li><p>To load a dataset, use <cite>get_dataset</cite> function. For example, to load AG’s news dataset, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span>  <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;ag&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>The trainset and testset are both dicts. The dict looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Apple releases its latest cell phone.&quot;</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>To sub-sample 100 examples from training set, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subsampled_dataset</span> <span class="o">=</span> <span class="n">subsample_dataset</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>To convert a dataset dict to a <code class="docutils literal notranslate"><span class="pre">torch.IterableDataset</span></code> for BERT model, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">iterable_dataset</span> <span class="o">=</span> <span class="n">DatasetForBert</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">);</span>
</pre></div>
</div>
</li>
</ul>
<p>For more details, see <code class="docutils literal notranslate"><span class="pre">https://dai-lab.github.io/fibber/</span></code></p>
<dl class="py class">
<dt id="fibber.datasets.dataset_utils.DatasetForBert">
<em class="property">class </em><code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">DatasetForBert</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">model_init</span></em>, <em class="sig-param"><span class="n">batch_size</span></em>, <em class="sig-param"><span class="n">exclude</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">masked_lm</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">masked_lm_ratio</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">seed</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#DatasetForBert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.DatasetForBert" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.dataset.IterableDataset</span></code></p>
<p>Create a <code class="docutils literal notranslate"><span class="pre">torch.IterableDataset</span></code> for a BERT model.</p>
<p>The module is an iterator that yields infinite batches from the dataset. To construct a
batch, we randomly sample a few examples with similar length. Then we pad all selected
examples to the same length <code class="docutils literal notranslate"><span class="pre">L</span></code>. Then we construct a tuple of 4 or 5 tensors. All
tensors are on CPU.</p>
<p>Each example starts with <code class="docutils literal notranslate"><span class="pre">[CLS]</span></code>, and ends with <code class="docutils literal notranslate"><span class="pre">[SEP]</span></code>. If there are two parts in
the input, the two parts are separated by <code class="docutils literal notranslate"><span class="pre">[SEP]</span></code>.</p>
<p>__iter__(self):</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p>A tuple of tensors.</p>
<ul class="simple">
<li><p>The first tensor is an int tensor of size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">L)</span></code>, representing
word ids. Each row of this tensor correspond to one example in the dataset.
If <code class="docutils literal notranslate"><span class="pre">masked_lm</span> <span class="pre">==</span> <span class="pre">True</span></code>, the tensor stores the masked text.</p></li>
<li><p>The second tensor is an int tensor of size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">L)</span></code>, representing
the text length. Each entry is 1 if the corresponding position is text, and it
is 0 if the position is padding.</p></li>
<li><p>The third tensor is an int tensor of size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">L)</span></code>, representing the
token type. The token type is 0 if current position is in the first part of the
input text. And it is 1 if current position is in the second part of the input.
For padding positions, token type is 0.</p></li>
<li><p>The forth tensor an int tensor of size <code class="docutils literal notranslate"><span class="pre">(batch_size,)</span></code>, representing the
classification label.</p></li>
<li><p>(optional) If <code class="docutils literal notranslate"><span class="pre">masked_lm</span> <span class="pre">==</span> <span class="pre">True</span></code>, the fifth tensor is a tensor of size
<code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">L)</span></code>. Each entry in this tensor is either -100 if the position is
not masked, or the correct word if the position is masked. Note that, a masked
position is not always a <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code> token in the first tensor. With 80%
probability, it is a <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code>. With 10% probability, it is the original word.
And with 10% probability, it is a random word.</p></li>
</ul>
</dd>
</dl>
<p>Initialize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>dict</em>) – a dataset dict.</p></li>
<li><p><strong>model_init</strong> (<em>str</em>) – the pre-trained model name. select from <code class="docutils literal notranslate"><span class="pre">['bert-base-cased',</span>
<span class="pre">'bert-base-uncased',</span> <span class="pre">'bert-large-cased',</span> <span class="pre">and</span> <span class="pre">'bert-large-uncased']</span></code>.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – the batch size in each step.</p></li>
<li><p><strong>exclude</strong> (<em>int</em>) – exclude one category from the data.
Use -1 (default) to include all categories.</p></li>
<li><p><strong>masked_lm</strong> (<em>bool</em>) – whether to randomly replace words with mask tokens.</p></li>
<li><p><strong>masked_lm_ratio</strong> (<em>float</em>) – the ratio of random masks. Ignored when masked_lm is False.</p></li>
<li><p><strong>seed</strong> – random seed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.datasets.dataset_utils.get_dataset">
<code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">get_dataset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset_name</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#get_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Load dataset from fibber root directory.</p>
<p>Users should make sure the data is downloaded to the <code class="docutils literal notranslate"><span class="pre">datasets</span></code> folder in fibber root
dir (default: <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets</span></code>). Otherwise, assertion error is raised.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataset_name</strong> (<em>str</em>) – the name of the dataset. See <code class="docutils literal notranslate"><span class="pre">https://dai-lab.github.io/fibber/</span></code>
for a full list of built-in datasets.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the function returns a tuple of two dict, representing the training set and
test set respectively.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(dict, dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.datasets.dataset_utils.get_demo_dataset">
<code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">get_demo_dataset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#get_demo_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.get_demo_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>download demo dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>trainset and testset.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(dict, dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.datasets.dataset_utils.subsample_dataset">
<code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">subsample_dataset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#subsample_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.subsample_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Sub-sample a dataset to <cite>n</cite> examples.</p>
<p>Data is selected evenly and randomly from each category. Data in each category is sorted by
its md5 hash value. The top <code class="docutils literal notranslate"><span class="pre">(n</span> <span class="pre">//</span> <span class="pre">k)</span></code> examples from each category are included in the
sub-sampled dataset, where <code class="docutils literal notranslate"><span class="pre">k</span></code> is the number of categories.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">n</span></code> is not divisible by <code class="docutils literal notranslate"><span class="pre">k</span></code>, one more data is sampled from the first <code class="docutils literal notranslate"><span class="pre">(n</span> <span class="pre">%</span> <span class="pre">k)</span></code>
categories.</p>
<p>If the dataset has less than <code class="docutils literal notranslate"><span class="pre">n</span></code> examples, a copy of the original dataset will be returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>dict</em>) – a dataset dict.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – the size of the sub-sampled dataset.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a sub-sampled dataset as a dict.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.datasets.dataset_utils.text_md5">
<code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">text_md5</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#text_md5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.text_md5" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes and returns the md5 hash of a str.</p>
</dd></dl>

<dl class="py function">
<dt id="fibber.datasets.dataset_utils.verify_dataset">
<code class="sig-prename descclassname">fibber.datasets.dataset_utils.</code><code class="sig-name descname">verify_dataset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/datasets/dataset_utils.html#verify_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.datasets.dataset_utils.verify_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Verify if the dataset dict contains necessary fields.</p>
<p>Assertion error is raised if there are missing or incorrect fields.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataset</strong> (<em>dict</em>) – a dataset dict.</p>
</dd>
</dl>
</dd></dl>

</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="fibber.datasets.html" title="previous page">fibber.datasets package</a>
    <a class='right-next' id="next-link" href="fibber.datasets.download_datasets.html" title="next page">fibber.datasets.download_datasets module</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>