
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>fibber.paraphrase_strategies.bert_sampling_strategy module &#8212; fibber 0.1.2 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/dai-logo-white.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fibber.paraphrase_strategies.bert_sampling_utils_lm module" href="fibber.paraphrase_strategies.bert_sampling_utils_lm.html" />
    <link rel="prev" title="fibber.paraphrase_strategies package" href="fibber.paraphrase_strategies.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../index.html">
    
      <img src="../_static/dai-logo-white-200.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../readme.html">Fibber</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../benchmark.html">Benchmark</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="fibber.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../contributing.html">Contributing</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../authors.html">Credits</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../history.html">History</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/dai-lab/fibber" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="fibber.benchmark.html">fibber.benchmark package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.datasets.html">fibber.datasets package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.metrics.html">fibber.metrics package</a>
                </li>
            
          
            
  
                <li class="active">
                    <a href="fibber.paraphrase_strategies.html">fibber.paraphrase_strategies package</a>
                    <ul>
                    
                        <li class="active">
                            <a href="">fibber.paraphrase_strategies.bert_sampling_strategy module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.bert_sampling_utils_lm.html">fibber.paraphrase_strategies.bert_sampling_utils_lm module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.bert_sampling_utils_text_parser.html">fibber.paraphrase_strategies.bert_sampling_utils_text_parser module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.bert_sampling_utils_wpe.html">fibber.paraphrase_strategies.bert_sampling_utils_wpe module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.identity_strategy.html">fibber.paraphrase_strategies.identity_strategy module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.random_strategy.html">fibber.paraphrase_strategies.random_strategy module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.strategy_base.html">fibber.paraphrase_strategies.strategy_base module</a>
                        </li>
                    
                        <li class="">
                            <a href="fibber.paraphrase_strategies.textfooler_strategy.html">fibber.paraphrase_strategies.textfooler_strategy module</a>
                        </li>
                    
                    </ul>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.resources.html">fibber.resources package</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.download_utils.html">fibber.download_utils module</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.fibber.html">fibber.fibber module</a>
                </li>
            
          
            
                <li class="">
                    <a href="fibber.log.html">fibber.log module</a>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-fibber.paraphrase_strategies.bert_sampling_strategy">
<span id="fibber-paraphrase-strategies-bert-sampling-strategy-module"></span><h1>fibber.paraphrase_strategies.bert_sampling_strategy module<a class="headerlink" href="#module-fibber.paraphrase_strategies.bert_sampling_strategy" title="Permalink to this headline">Â¶</a></h1>
<dl class="py class">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy">
<em class="property">class </em><code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">BertSamplingStrategy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arg_dict</span></em>, <em class="sig-param"><span class="n">dataset_name</span></em>, <em class="sig-param"><span class="n">strategy_gpu_id</span></em>, <em class="sig-param"><span class="n">output_dir</span></em>, <em class="sig-param"><span class="n">metric_bundle</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#BertSamplingStrategy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="fibber.paraphrase_strategies.strategy_base.html#fibber.paraphrase_strategies.strategy_base.StrategyBase" title="fibber.paraphrase_strategies.strategy_base.StrategyBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">fibber.paraphrase_strategies.strategy_base.StrategyBase</span></code></a></p>
<p>Initialize the paraphrase_strategies.</p>
<p>This function initialize the <code class="docutils literal notranslate"><span class="pre">self._strategy_config</span></code>, <code class="docutils literal notranslate"><span class="pre">self._metric_bundle</span></code>,
<code class="docutils literal notranslate"><span class="pre">self._device</span></code>, <code class="docutils literal notranslate"><span class="pre">self._output_dir</span></code>, <code class="docutils literal notranslate"><span class="pre">self._dataset_name</span></code>.</p>
<p><strong>You should not overwrite this function.</strong></p>
<ul class="simple">
<li><p>self._strategy_config (dict): a dictionary that stores the strategy name and all
hyperparameter values. The dict is also saved to the results.</p></li>
<li><p>self._metric_bundle (MetricBundle): the metrics that will be used to evaluate
paraphrases. Strategies can compute metrics during paraphrasing.</p></li>
<li><p>self._device (torch.Device): any computation that requires a GPU accelerator should
use this device.</p></li>
<li><p>self._output_dir (str): the dir name where the strategy can save files.</p></li>
<li><p>self._dataset_name (str): the dataset name.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arg_dict</strong> (<em>dict</em>) â all args load from command line.</p></li>
<li><p><strong>dataset_name</strong> (<em>str</em>) â the name of the dataset.</p></li>
<li><p><strong>strategy_gpu_id</strong> (<em>int</em>) â the gpu id to run the strategy.</p></li>
<li><p><strong>output_dir</strong> (<em>str</em>) â a directory to save any models or temporary files.</p></li>
<li><p><strong>metric_bundle</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.MetricBundle" title="fibber.metrics.MetricBundle"><em>MetricBundle</em></a>) â a MetricBundle object.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">trainset</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#BertSamplingStrategy.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Fit the paraphrase strategy on a training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>trainset</strong> (<em>dict</em>) â a fibber dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy.paraphrase_example">
<code class="sig-name descname">paraphrase_example</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data_record</span></em>, <em class="sig-param"><span class="n">field_name</span></em>, <em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#BertSamplingStrategy.paraphrase_example"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.BertSamplingStrategy.paraphrase_example" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Paraphrase one data record.</p>
<p>This function should be overwritten by subclasses. When overwriting this class, you can
use <code class="docutils literal notranslate"><span class="pre">self._strategy_config</span></code>, <code class="docutils literal notranslate"><span class="pre">self._metric_bundle</span></code>,  <code class="docutils literal notranslate"><span class="pre">self._device</span></code>,
<code class="docutils literal notranslate"><span class="pre">self._output_dir</span></code>, and <code class="docutils literal notranslate"><span class="pre">self._dataset_name</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_record</strong> (<em>dict</em>) â a dict storing one data of a dataset.</p></li>
<li><p><strong>field_name</strong> (<em>str</em>) â the field needed to be paraphrased.</p></li>
<li><p><strong>n</strong> (<em>int</em>) â number of paraphrases.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list contain at most n strings.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>([str,])</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.all_accept_criteria">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">all_accept_criteria</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">candidate_ids</span></em>, <em class="sig-param"><span class="n">stats</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#all_accept_criteria"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.all_accept_criteria" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Always accept proposed words.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>candidate_ids</strong> (<em>torch.Tensor</em>) â proposed word ids in this sampling step with
size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">pos_ed-pos_st)</span></code>.</p></li>
<li><p><strong>stats</strong> (<em>dict</em>) â a dict to keep track the accept rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>(np.array, None)</dt><dd><p>np.array is the same as candidate_ids.
None means this criteria does not have any state.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.allow_list_constraint">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">allow_list_constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">allow_list</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#allow_list_constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.allow_list_constraint" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.bert_criteria_score">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">bert_criteria_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paraphrases</span></em>, <em class="sig-param"><span class="n">context</span></em>, <em class="sig-param"><span class="n">label</span></em>, <em class="sig-param"><span class="n">bert_metric</span></em>, <em class="sig-param"><span class="n">bert_weight</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#bert_criteria_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.bert_criteria_score" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.gpt2_criteria_score">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">gpt2_criteria_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">origin</span></em>, <em class="sig-param"><span class="n">paraphrases</span></em>, <em class="sig-param"><span class="n">gpt2_metric</span></em>, <em class="sig-param"><span class="n">gpt2_weight</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#gpt2_criteria_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.gpt2_criteria_score" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Estimate the score of a sentence using USE.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin</strong> (<em>str</em>) â original sentence.</p></li>
<li><p><strong>paraphrases</strong> (<em>[</em><em>str</em><em>]</em>) â a list of paraphrases.</p></li>
<li><p><strong>gpt2_metric</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.GPT2GrammarQuality" title="fibber.metrics.GPT2GrammarQuality"><em>GPT2GrammarQuality</em></a>) â a GPT2GrammarQuality metric object.</p></li>
<li><p><strong>gpt2_weight</strong> (<em>float</em>) â the weight parameter for the criteria.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of size <code class="docutils literal notranslate"><span class="pre">(batch_size,)</span></code>. All entries <code class="docutils literal notranslate"><span class="pre">&lt;=0</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(np.array)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.joint_weighted_criteria">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">joint_weighted_criteria</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em>, <em class="sig-param"><span class="n">data_record</span></em>, <em class="sig-param"><span class="n">field_name</span></em>, <em class="sig-param"><span class="n">origin</span></em>, <em class="sig-param"><span class="n">batch_tensor</span></em>, <em class="sig-param"><span class="n">pos_st</span></em>, <em class="sig-param"><span class="n">pos_ed</span></em>, <em class="sig-param"><span class="n">previous_ids</span></em>, <em class="sig-param"><span class="n">candidate_ids</span></em>, <em class="sig-param"><span class="n">use_metric</span></em>, <em class="sig-param"><span class="n">use_threshold</span></em>, <em class="sig-param"><span class="n">use_weight</span></em>, <em class="sig-param"><span class="n">bert_metric</span></em>, <em class="sig-param"><span class="n">bert_weight</span></em>, <em class="sig-param"><span class="n">gpt2_metric</span></em>, <em class="sig-param"><span class="n">gpt2_weight</span></em>, <em class="sig-param"><span class="n">burnin_weight</span></em>, <em class="sig-param"><span class="n">stats</span></em>, <em class="sig-param"><span class="n">state</span></em>, <em class="sig-param"><span class="n">device</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#joint_weighted_criteria"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.joint_weighted_criteria" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Accept or reject candidate word using the joint weighted criteria.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokenizer</strong> (<em>transformers.BertTokenizer</em>) â a bert tokenizer.</p></li>
<li><p><strong>data_record</strong> (<em>dict</em>) â the data record dict.</p></li>
<li><p><strong>field_name</strong> (<em>str</em>) â the field to rewritten.</p></li>
<li><p><strong>origin</strong> (<em>str</em>) â original text. Same as <code class="docutils literal notranslate"><span class="pre">data_record[field_name]</span></code>.</p></li>
<li><p><strong>batch_tensor</strong> (<em>torch.Tensor</em>) â tensor of a batch of text with size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">L)</span></code>.</p></li>
<li><p><strong>pos_st</strong> (<em>int</em>) â the start position of sampling (include).</p></li>
<li><p><strong>pos_ed</strong> (<em>int</em>) â the end position of sampling (exclude).</p></li>
<li><p><strong>previous_ids</strong> (<em>torch.Tensor</em>) â word ids before current step of sampling with
size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">pos_ed-pos_st)</span></code>.</p></li>
<li><p><strong>candidate_ids</strong> (<em>torch.Tensor</em>) â proposed word ids in this sampling step with
size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">pos_ed-pos_st)</span></code>.</p></li>
<li><p><strong>use_metric</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.USESemanticSimilarity" title="fibber.metrics.USESemanticSimilarity"><em>USESemanticSimilarity</em></a>) â a universal sentence encoder metric object.</p></li>
<li><p><strong>use_threshold</strong> (<em>float</em>) â the universal sentence encoder similarity threshold.</p></li>
<li><p><strong>use_weight</strong> (<em>float</em>) â the weight for USE criteria score.</p></li>
<li><p><strong>bert_metric</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.BertClfPrediction" title="fibber.metrics.BertClfPrediction"><em>BertClfPrediction</em></a>) â a BertClfPrediction metric.</p></li>
<li><p><strong>bert_weight</strong> (<em>float</em>) â the weight for BERT criteria score.</p></li>
<li><p><strong>gpt2_metric</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.GPT2GrammarQuality" title="fibber.metrics.GPT2GrammarQuality"><em>GPT2GrammarQuality</em></a>) â a GPT2GrammarQuality metric.</p></li>
<li><p><strong>gpt2_weight</strong> (<em>float</em>) â the weight for GPT2 criteria score.</p></li>
<li><p><strong>burnin_weight</strong> (<em>float</em>) â the discount factor.</p></li>
<li><p><strong>stats</strong> (<em>dict</em>) â a dict to keep track the accept rate.</p></li>
<li><p><strong>state</strong> (<em>np.array</em>) â the state is criteria score from the previous iteration.</p></li>
<li><p><strong>device</strong> (<em>torch.Device</em>) â the device that batch_tensor is on.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl>
<dt>(np.array, np.array)</dt><dd><dl class="simple">
<dt>a 2-D int array of size <code class="docutils literal notranslate"><span class="pre">batch_size,</span> <span class="pre">pos_ed</span> <span class="pre">-</span> <span class="pre">pos_st</span></code>. Each row <code class="docutils literal notranslate"><span class="pre">i</span></code> is</dt><dd><p>either <code class="docutils literal notranslate"><span class="pre">previous_ids[i,</span> <span class="pre">:]</span></code> if rejected, or <code class="docutils literal notranslate"><span class="pre">candidate_ids[i,</span> <span class="pre">:]</span></code> if accepted.</p>
</dd>
</dl>
<p>a 1-D float array of criteria score.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.none_constraint">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">none_constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">kargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#none_constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.none_constraint" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.process_text">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">process_text</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">text</span></em>, <em class="sig-param"><span class="n">patterns</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#process_text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.process_text" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Processing the text using regex patterns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) â the str to be post processed.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.sample_word_from_logits">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">sample_word_from_logits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">logits</span></em>, <em class="sig-param"><span class="n">temperature</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em class="sig-param"><span class="n">top_k</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#sample_word_from_logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.sample_word_from_logits" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sample a word from a distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<em>torch.Tensor</em>) â tensor of logits with size <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">vocab_size)</span></code>.</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) â the temperature of softmax. The PMF is
<code class="docutils literal notranslate"><span class="pre">softmax(logits/temperature)</span></code>.</p></li>
<li><p><strong>top_k</strong> (<em>int</em>) â if <code class="docutils literal notranslate"><span class="pre">k&gt;0</span></code>, only sample from the top k most probable words.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.tostring">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">tostring</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tokenizer</span></em>, <em class="sig-param"><span class="n">seq</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#tostring"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.tostring" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Convert a sequence of word ids to a sentence. The post prossing is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tokenizer</strong> (<em>transformers.BertTokenizer</em>) â a BERT tokenizer.</p></li>
<li><p><strong>seq</strong> (<em>list</em>) â a list-like sequence of word ids.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.use_criteria_score">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">use_criteria_score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">origin</span></em>, <em class="sig-param"><span class="n">paraphrases</span></em>, <em class="sig-param"><span class="n">use_metric</span></em>, <em class="sig-param"><span class="n">use_threshold</span></em>, <em class="sig-param"><span class="n">use_weight</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#use_criteria_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.use_criteria_score" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Estimate the score of a sentence using USE.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin</strong> (<em>str</em>) â original sentence.</p></li>
<li><p><strong>paraphrases</strong> (<em>[</em><em>str</em><em>]</em>) â a list of paraphrases.</p></li>
<li><p><strong>use_metric</strong> (<a class="reference internal" href="fibber.metrics.html#fibber.metrics.USESemanticSimilarity" title="fibber.metrics.USESemanticSimilarity"><em>USESemanticSimilarity</em></a>) â a universal sentence encoder metric object.</p></li>
<li><p><strong>use_threshold</strong> (<em>float</em>) â the universal sentence encoder similarity threshold.</p></li>
<li><p><strong>use_weight</strong> (<em>float</em>) â the weight parameter for the criteria.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of size <code class="docutils literal notranslate"><span class="pre">(batch_size,)</span></code>. All entries <code class="docutils literal notranslate"><span class="pre">&lt;=0</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(np.array)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="fibber.paraphrase_strategies.bert_sampling_strategy.wpe_constraint">
<code class="sig-prename descclassname">fibber.paraphrase_strategies.bert_sampling_strategy.</code><code class="sig-name descname">wpe_constraint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target_emb</span></em>, <em class="sig-param"><span class="n">word_embs</span></em>, <em class="sig-param"><span class="n">batch_tensor</span></em>, <em class="sig-param"><span class="n">pos</span></em>, <em class="sig-param"><span class="n">wpe_threshold</span></em>, <em class="sig-param"><span class="n">wpe_weight</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/fibber/paraphrase_strategies/bert_sampling_strategy.html#wpe_constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fibber.paraphrase_strategies.bert_sampling_strategy.wpe_constraint" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="fibber.paraphrase_strategies.html" title="previous page">fibber.paraphrase_strategies package</a>
    <a class='right-next' id="next-link" href="fibber.paraphrase_strategies.bert_sampling_utils_lm.html" title="next page">fibber.paraphrase_strategies.bert_sampling_utils_lm module</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>