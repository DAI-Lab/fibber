
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Fibber &#8212; fibber 0.0.1.dev0 documentation</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="_static/dai-logo-white.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="fibber package" href="api/fibber.html" />
    <link rel="prev" title="Fibber" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="index.html">
    
      <img src="_static/dai-logo-white-200.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item active">
            <a class="nav-link" href="">Fibber</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="api/fibber.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="contributing.html">Contributing</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="authors.html">Credits</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="history.html">History</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/sdv-dev/fibber" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
          
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#" class="nav-link">Fibber</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#overview" class="nav-link">Overview</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#install" class="nav-link">Install</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#requirements" class="nav-link">Requirements</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#install-from-pypi" class="nav-link">Install from PyPI</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#use-without-install" class="nav-link">Use without install</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#install-from-source" class="nav-link">Install from source</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#quickstart" class="nav-link">Quickstart</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#benchmark-result" class="nav-link">Benchmark result</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#specifications" class="nav-link">Specifications</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#id3" class="nav-link">Datasets</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#dataset-format" class="nav-link">Dataset format</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#download-datasets" class="nav-link">Download datasets</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#supported-strategies" class="nav-link">Supported strategies</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#output-format" class="nav-link">Output format</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#intermediate-result" class="nav-link">Intermediate result</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#result-with-metrics" class="nav-link">Result with metrics</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#what-s-next" class="nav-link">What’s next?</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <p align="left">
<img width=15% src="https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png" alt=“DAI-Lab” />
<i>An open source project from Data to AI Lab at MIT.</i>
</p><p><span class="raw-html-m2r"><!-- Uncomment these lines after releasing the package to PyPI for version and downloads badges --></span>
<span class="raw-html-m2r"><!--[![PyPI Shield](https://img.shields.io/pypi/v/fibber.svg)](https://pypi.python.org/pypi/fibber)--></span>
<span class="raw-html-m2r"><!--[![Downloads](https://pepy.tech/badge/fibber)](https://pepy.tech/project/fibber)--></span></p>
<a class="reference external image-reference" href="https://travis-ci.org/DAI-Lab/fibber"><img alt="Travis CI Shield" src="https://travis-ci.com/DAI-Lab/fibber.svg?token=g6BnJQz9Aaqdj1paqcNM&amp;branch=master&amp;status=started" /></a>
<a class="reference external image-reference" href="https://codecov.io/gh/DAI-Lab/fibber"><img alt="Coverage Status" src="https://codecov.io/gh/DAI-Lab/fibber/branch/master/graph/badge.svg" /></a>
<div class="section" id="fibber">
<h1>Fibber<a class="headerlink" href="#fibber" title="Permalink to this headline">¶</a></h1>
<p>Fibber is a library to evaluate different strategies to paraphrase natural language, especially how these strategies can break text classifiers without changing the meaning of a sentence.</p>
<ul class="simple">
<li><p>Documentation: <a class="reference external" href="https://DAI-Lab.github.io/fibber">https://DAI-Lab.github.io/fibber</a></p></li>
<li><p>GitHub: <a class="reference external" href="https://github.com/DAI-Lab/fibber">https://github.com/DAI-Lab/fibber</a></p></li>
</ul>
</div>
<div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<p>Fibber is a library to evaluate different strategies to paraphrase natural language. In this library, we have several built-in paraphrasing strategies. We also have a benchmark framework to evaluate the quality of paraphrase. In particular, we use the GPT2 language model to measure how meaningful is the paraphrased text. We use a universal sentence encoder to evaluate the semantic similarity between original and paraphrased text. We also train a BERT classifier on the original dataset, and check of paraphrased sentences can break the text classifier.</p>
</div>
<div class="section" id="install">
<h1>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h1>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<p><strong>fibber</strong> has been developed and tested on <a class="reference external" href="https://www.python.org/downloads/">Python 3.6, 3.7 and 3.8</a></p>
<p>Also, although it is not strictly required, the usage of <a class="reference external" href="https://docs.conda.io/en/latest/miniconda.html">conda</a>
is highly recommended to avoid interfering with other software installed in the system
in which <strong>fibber</strong> is run.</p>
<p>These are the minimum commands needed to create a conda environment using python3.6 for <strong>fibber</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># First you should install conda.</span>
conda create -n fibber_env <span class="nv">python</span><span class="o">=</span><span class="m">3</span>.6
</pre></div>
</div>
<p>Afterward, you have to execute this command to activate the environment:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda activate fibber_env
</pre></div>
</div>
<p><strong>Then you should install tensorflow and pytorch.</strong> Please follow the instructions for <a class="reference external" href="https://www.tensorflow.org/install">tensorflow</a> and <a class="reference external" href="https://pytorch.org">pytorch</a>. Fibber requires <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2.0.0</span></code> and <code class="docutils literal notranslate"><span class="pre">pytorch&gt;=1.5.0</span></code>.</p>
<p>Remember to execute <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">fibber_env</span></code> every time you start a new console to work on <strong>fibber</strong>!</p>
</div>
<div class="section" id="install-from-pypi">
<h2>Install from PyPI<a class="headerlink" href="#install-from-pypi" title="Permalink to this headline">¶</a></h2>
<p>After creating the conda environment and activating it, we recommend using
<a class="reference external" href="https://pip.pypa.io/en/stable/">pip</a> in order to install <strong>fibber</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install fibber
</pre></div>
</div>
<p>This will pull and install the latest stable release from <a class="reference external" href="https://pypi.org/">PyPI</a>.</p>
</div>
<div class="section" id="use-without-install">
<h2>Use without install<a class="headerlink" href="#use-without-install" title="Permalink to this headline">¶</a></h2>
<p>If you are using this project for research purpose and want to make changes to the code,
you can install all requirements by</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone git@github.com:DAI-Lab/fibber.git
<span class="nb">cd</span> fibber
pip install --requirement requirement.txt
</pre></div>
</div>
<p>Then you can use fibber by</p>
<div class="highlight-base notranslate"><div class="highlight"><pre><span></span>python -m fibber.datasets.download_datasets
python -m fibber.benchmark.benchmark
</pre></div>
</div>
<p>In this case, any changes you made on the code will take effect immediately.</p>
</div>
<div class="section" id="install-from-source">
<h2>Install from source<a class="headerlink" href="#install-from-source" title="Permalink to this headline">¶</a></h2>
<p>With your conda environment activated, you can clone the repository and install it from
source by running <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">install</span></code> on the <code class="docutils literal notranslate"><span class="pre">stable</span></code> branch:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone git@github.com:DAI-Lab/fibber.git
<span class="nb">cd</span> fibber
git checkout stable
make install
</pre></div>
</div>
</div>
</div>
<div class="section" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h1>
<p>In this short tutorial, we will guide you through a series of steps that will help you
getting started with <strong>fibber</strong>.</p>
<p><a href="#id1"><span class="problematic" id="id2">**</span></a>(1) <a class="reference external" href="#Install">Install Fibber</a>**</p>
<p><strong>(2) Download datasets</strong></p>
<p>Please use the following command to download all datasets.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.datasets.download_datasets
</pre></div>
</div>
<p>All datasets will be downloaded and stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets</span></code>.</p>
<p><strong>(3) Execute the benchmark on one dataset using one paraphrase strategy.</strong></p>
<p>The following command will run the <code class="docutils literal notranslate"><span class="pre">random</span></code> strategy on the <code class="docutils literal notranslate"><span class="pre">ag</span></code> dataset. To use other datasets, see the <a class="reference external" href="#Datasets">datasets</a> section.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.benchmark.benchmark <span class="se">\</span>
    --dataset ag <span class="se">\</span>
    --strategy RandomStrategy <span class="se">\</span>
    --output_dir exp-ag <span class="se">\</span>
    --num_paraphrases_per_text <span class="m">20</span> <span class="se">\</span>
    --subsample_testset <span class="m">100</span> <span class="se">\</span>
    --gpt2_gpu <span class="m">0</span> <span class="se">\</span>
    --bert_gpu <span class="m">0</span> <span class="se">\</span>
    --use_gpu <span class="m">0</span> <span class="se">\</span>
    --bert_clf_steps <span class="m">20000</span>
</pre></div>
</div>
<p>It first subsamples the test set to <code class="docutils literal notranslate"><span class="pre">100</span></code> examples, then generates <code class="docutils literal notranslate"><span class="pre">20</span></code> paraphrases for each example. During this process, the paraphrased sentences will be stored at <code class="docutils literal notranslate"><span class="pre">exp-ag/ag-RandomStrategy-&lt;date&gt;-&lt;time&gt;-tmp.json</span></code>.</p>
<p>Then the pipeline will initialize all the evaluation metrics.</p>
<ul class="simple">
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">GPT2</span></code> model to evaluate if a sentence is meaningful. The <code class="docutils literal notranslate"><span class="pre">GPT2</span></code> language model will be executed on <code class="docutils literal notranslate"><span class="pre">gpt2_gpu</span></code>. You should change the argument to a proper GPU id.</p></li>
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">Universal</span> <span class="pre">sentence</span> <span class="pre">encoder</span> <span class="pre">(USE)</span></code> model to measure the similarity between two paraphrased sentences and the original sentence. The <code class="docutils literal notranslate"><span class="pre">USE</span></code> will be executed on <code class="docutils literal notranslate"><span class="pre">use_gpu</span></code>. You should change the argument to a proper GPU id.</p></li>
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">BERT</span></code> model to predict the classification label for paraphrases. The <code class="docutils literal notranslate"><span class="pre">BERT</span></code> will be executed on <code class="docutils literal notranslate"><span class="pre">bert_gpu</span></code>. You should change the argument to a proper GPU id. <strong>Note that the BERT classifier will be trained for the first time you execute the pipeline. Then the trained model will be saved at ``~/.fibber/bert_clf/&lt;dataset_name&gt;/``. Because of the training, it will use more GPU memory than GPT2 and USE. So assign BERT to a separate GPU if you have multiple GPUs.</strong></p></li>
</ul>
<p>After the execution, the evaluation metric for each of the paraphrases will be stored at <code class="docutils literal notranslate"><span class="pre">exp-ag/ag-RandomStrategy-&lt;date&gt;-&lt;time&gt;-with-metrics.json</span></code>.</p>
<p>The aggregated result will be stored as a row at <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/detailed.csv</span></code>.</p>
<p><strong>(4) Generate overview result.</strong></p>
<p>We use the number of wins to compare different strategies. To generate the overview table, use the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.benchmark.make_overview
</pre></div>
</div>
<p>The overview table will be stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/overview.csv</span></code>.</p>
<p>Before running this command, please verify <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/detailed.csv</span></code>. Each strategy must not have more than one executions on one dataset. Otherwise, the script will raise assertion errors.</p>
</div>
<div class="section" id="benchmark-result">
<h1>Benchmark result<a class="headerlink" href="#benchmark-result" title="Permalink to this headline">¶</a></h1>
<p>The following table shows the benchmarking result. (Here we show the number of wins.)</p>
<table class="table">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>1_paraphrase_strategy_name</p></th>
<th class="head"><p>USESemanticSimilarity_mean</p></th>
<th class="head"><p>GPT2GrammarQuality_mean</p></th>
<th class="head"><p>3_ParaphraseAcc_usesim0.90_ppl2</p></th>
<th class="head"><p>4_ParaphraseAcc_usesim0.85_ppl5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>IdentityStrategy</p></td>
<td><p>7</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>RandomStrategy</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
</tr>
</tbody>
</table>
<p>For detailed tables, see <a class="reference external" href="https://docs.google.com/spreadsheets/d/1B_5RiMfndNVhxZLX5ykMqt5SCjpy3MxOovBi_RL41Fw/edit?usp=sharing">Google Sheet</a>.</p>
</div>
<div class="section" id="specifications">
<h1>Specifications<a class="headerlink" href="#specifications" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id3">
<h2>Datasets<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Here is the information about datasets in fibber.</p>
<table class="table">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Name</p></th>
<th class="head"><p>Size (train/test)</p></th>
<th class="head"><p>Classes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Topic Classification</p></td>
<td><p><a class="reference external" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html">ag</a></p></td>
<td><p>120k / 7.6k</p></td>
<td><p>World / Sport / Business / Sci-Tech</p></td>
</tr>
<tr class="row-odd"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="http://www.cs.cornell.edu/people/pabo/movie-review-data/">mr</a></p></td>
<td><p>9k / 1k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-even"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="https://academictorrents.com/details/66ab083bda0c508de6c641baabb1ec17f72dc480">yelp</a></p></td>
<td><p>160k / 38k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-odd"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="https://ai.stanford.edu/~amaas/data/sentiment/">imdb</a></p></td>
<td><p>25k / 25k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-even"><td><p>Natural Language Inference</p></td>
<td><p><a class="reference external" href="https://nlp.stanford.edu/projects/snli/">snli</a></p></td>
<td><p>570k / 10k</p></td>
<td><p>Entailment / Neutral / Contradict</p></td>
</tr>
<tr class="row-odd"><td><p>Natural Language Inference</p></td>
<td><p><a class="reference external" href="https://cims.nyu.edu/~sbowman/multinli/">mnli</a></p></td>
<td><p>433k / 10k</p></td>
<td><p>Entailment / Neutral / Contradict</p></td>
</tr>
</tbody>
</table>
<p>Note that mnli has two configurations. Use <code class="docutils literal notranslate"><span class="pre">mnli</span></code> for matched testset, and <code class="docutils literal notranslate"><span class="pre">mnli_mis</span></code> for mismatched testset.</p>
<div class="section" id="dataset-format">
<h3>Dataset format<a class="headerlink" href="#dataset-format" title="Permalink to this headline">¶</a></h3>
<p>Each dataset is stored in multiple JSON files. For example, the ag dataset is stored in <code class="docutils literal notranslate"><span class="pre">train.json</span></code> and <code class="docutils literal notranslate"><span class="pre">test.json</span></code>.</p>
<p>The JSON file contains the following fields:</p>
<ul class="simple">
<li><p>label_mapping: a list of strings. The label_mapping maps an integer label to the actual meaning of that label. This list is not used in the algorithm.</p></li>
<li><p>cased: a bool value indicates if it is a cased dataset or uncased dataset. Sentences in uncased datasets are all in lowercase.
paraphrase_field: choose from text0 and text1. Paraphrase_field indicates which sentence in each data record should be paraphrased.</p></li>
<li><p>data: a list of data records. Each data records contains:</p>
<ul>
<li><p>label: an integer indicating the classification label of the text.</p></li>
<li><p>text0:</p>
<ul>
<li><p>For topic and sentiment classification datasets, text0 stores the text to be classified.</p></li>
<li><p>For natural language inference datasets, text0 stores the premise.</p></li>
</ul>
</li>
<li><p>text1:</p>
<ul>
<li><p>For topic and sentiment classification datasets, this field is omitted.</p></li>
<li><p>For natural language inference datasets, text1 stores the hypothesis.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Apple releases its latest cell phone.&quot;</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="download-datasets">
<h3>Download datasets<a class="headerlink" href="#download-datasets" title="Permalink to this headline">¶</a></h3>
<p>We have scripts to help you easily download all datasets. We provide two options to download datasets:</p>
<ul>
<li><p><strong>Download data preprocessed by us.</strong> We preprocessed datasets and uploaded them to AWS. You can use the following command to download all datasets.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">fibber</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">download_datasets</span>
</pre></div>
</div>
<p>After executing the command, the dataset is stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/&lt;dataset_name&gt;/*.json</span></code>. For example, the ag dataset is stored in <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/ag/</span></code>. And there will be two sets <code class="docutils literal notranslate"><span class="pre">train.json</span></code> and <code class="docutils literal notranslate"><span class="pre">test.json</span></code> in the folder.</p>
</li>
<li><p><strong>Download and process data from the original source.</strong> You can also download the original dataset version and process it locally.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">fibber</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">download_datasets</span> <span class="o">--</span><span class="n">process_raw</span> <span class="mi">1</span>
</pre></div>
</div>
<p>This script will download data from the original source to <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/&lt;dataset_name&gt;/raw/</span></code> folder. And process the raw data to generate the JSON files.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="supported-strategies">
<h2>Supported strategies<a class="headerlink" href="#supported-strategies" title="Permalink to this headline">¶</a></h2>
<p>In this version, we implement three strategies</p>
<ul class="simple">
<li><p>IdentityStrategy:</p>
<ul>
<li><p>The identity strategy outputs the original text as its paraphrase.</p></li>
<li><p>This strategy generates exactly 1 paraphrase for each original text regardless of <code class="docutils literal notranslate"><span class="pre">--num_paraphrases_per_text</span></code> flag.</p></li>
</ul>
</li>
<li><p>RandomStrategy:</p>
<ul>
<li><p>The random strategy outputs the random shuffle of words in the original text.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="output-format">
<h2>Output format<a class="headerlink" href="#output-format" title="Permalink to this headline">¶</a></h2>
<p>During the benchmark process, we save results in several files.</p>
<div class="section" id="intermediate-result">
<h3>Intermediate result<a class="headerlink" href="#intermediate-result" title="Permalink to this headline">¶</a></h3>
<p>The intermediate result <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/&lt;dataset&gt;-&lt;strategy&gt;-&lt;date&gt;-&lt;time&gt;-tmp.json</span></code> stores the paraphrased sentences. Strategies can run for a few minutes (hours) on some datasets, so we save the result every 30 seconds. The file format is similar to the dataset file. For each data record, we add a new field, <code class="docutils literal notranslate"><span class="pre">text0_paraphrases</span></code> or <code class="docutils literal notranslate"><span class="pre">text1_paraphrases</span></code> depending o the <code class="docutils literal notranslate"><span class="pre">paraphrase_field</span></code>.</p>
<p>An example is as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span><span class="p">,</span>
      <span class="s2">&quot;text0_paraphrases&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="result-with-metrics">
<h3>Result with metrics<a class="headerlink" href="#result-with-metrics" title="Permalink to this headline">¶</a></h3>
<p>The result <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/&lt;dataset&gt;-&lt;strategy&gt;-&lt;date&gt;-&lt;time&gt;-with-metrics.json</span></code> stores the paraphrased sentences as well as metrics. Compute metrics may need a few minutes on some datasets, so we save the result every 30 seconds. The file format is similar to the intermediate file. For each data record, we add two new field, <code class="docutils literal notranslate"><span class="pre">original_text_metrics</span></code> and <code class="docutils literal notranslate"><span class="pre">paraphrase_metrics</span></code>.</p>
<p>An example is as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span><span class="p">,</span>
      <span class="s2">&quot;text0_paraphrases&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
      <span class="s2">&quot;original_text_metrics&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;EditingDistance&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;USESemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;GloVeSemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;GPT2GrammarQuality&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;BertClfPrediction&quot;</span><span class="p">:</span> <span class="mi">1</span>
      <span class="p">},</span>
      <span class="s2">&quot;paraphrase_metrics&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s2">&quot;EditingDistance&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
          <span class="s2">&quot;USESemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">0.91</span><span class="p">,</span>
          <span class="s2">&quot;GloVeSemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">0.94</span><span class="p">,</span>
          <span class="s2">&quot;GPT2GrammarQuality&quot;</span><span class="p">:</span> <span class="mf">2.3</span><span class="p">,</span>
          <span class="s2">&quot;BertClfPrediction&quot;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">},</span>
        <span class="o">...</span>
      <span class="p">]</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">original_text_metrics</span></code> stores a dict of several metrics. It compares the original text against itself. The <code class="docutils literal notranslate"><span class="pre">paraphrase_metrics</span></code> is a list of the same length as paraphrases in this data record. Each element in this list is a dict showing the comparison between the original text and one paraphrased text.</p>
</div>
</div>
</div>
<div class="section" id="what-s-next">
<h1>What’s next?<a class="headerlink" href="#what-s-next" title="Permalink to this headline">¶</a></h1>
<p>For more details about <strong>fibber</strong> and all its possibilities
and features, please check the <a class="reference external" href="https://DAI-Lab.github.io/fibber/">documentation site</a>.</p>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Fibber</a>
    <a class='right-next' id="next-link" href="api/fibber.html" title="next page">fibber package</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>