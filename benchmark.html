
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Benchmark &#8212; fibber 0.1.2 documentation</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="_static/dai-logo-white.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="fibber package" href="api/fibber.html" />
    <link rel="prev" title="Fibber" href="readme.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="index.html">
    
      <img src="_static/dai-logo-white-200.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="readme.html">Fibber</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href=""></a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="">Benchmark</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="api/fibber.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="contributing.html">Contributing</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="authors.html">Credits</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="history.html">History</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/dai-lab/fibber" target="_blank" rel="noopener">
              <span><i class="fab fa-github-square"></i></span>
            </a>
          </li>
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
          
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#quick-start" class="nav-link">Quick Start</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#id3" class="nav-link">Datasets</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#dataset-format" class="nav-link">Dataset format</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#download-datasets" class="nav-link">Download datasets</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#benchmark-result" class="nav-link">Benchmark result</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#output-format" class="nav-link">Output format</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#intermediate-result" class="nav-link">Intermediate result</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#result-with-metrics" class="nav-link">Result with metrics</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="benchmark">
<h1>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline">¶</a></h1>
<div class="section" id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this headline">¶</a></h2>
<p>In this short tutorial, we will guide you through a series of steps that will help you run benchmark on different strategies using fibber.</p>
<p><a href="#id1"><span class="problematic" id="id2">**</span></a>(1) <a class="reference external" href="#Install">Install Fibber</a>**</p>
<p><strong>(2) Download datasets</strong></p>
<p>Please use the following command to download all datasets.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.datasets.download_datasets
</pre></div>
</div>
<p>All datasets will be downloaded and stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets</span></code>.</p>
<p><strong>(3) Execute the benchmark on one dataset using one paraphrase strategy.</strong></p>
<p>The following command will run the <code class="docutils literal notranslate"><span class="pre">random</span></code> strategy on the <code class="docutils literal notranslate"><span class="pre">ag</span></code> dataset. To use other datasets, see the <a class="reference external" href="#Datasets">datasets</a> section.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.benchmark.benchmark <span class="se">\</span>
    --dataset ag <span class="se">\</span>
    --strategy RandomStrategy <span class="se">\</span>
    --output_dir exp-ag <span class="se">\</span>
    --num_paraphrases_per_text <span class="m">20</span> <span class="se">\</span>
    --subsample_testset <span class="m">100</span> <span class="se">\</span>
    --gpt2_gpu <span class="m">0</span> <span class="se">\</span>
    --bert_gpu <span class="m">0</span> <span class="se">\</span>
    --use_gpu <span class="m">0</span> <span class="se">\</span>
    --bert_clf_steps <span class="m">20000</span>
</pre></div>
</div>
<p>It first subsamples the test set to <code class="docutils literal notranslate"><span class="pre">100</span></code> examples, then generates <code class="docutils literal notranslate"><span class="pre">20</span></code> paraphrases for each example. During this process, the paraphrased sentences will be stored at <code class="docutils literal notranslate"><span class="pre">exp-ag/ag-RandomStrategy-&lt;date&gt;-&lt;time&gt;-tmp.json</span></code>.</p>
<p>Then the pipeline will initialize all the evaluation metrics.</p>
<ul class="simple">
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">GPT2</span></code> model to evaluate if a sentence is meaningful. The <code class="docutils literal notranslate"><span class="pre">GPT2</span></code> language model will be executed on <code class="docutils literal notranslate"><span class="pre">gpt2_gpu</span></code>. You should change the argument to a proper GPU id.</p></li>
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">Universal</span> <span class="pre">sentence</span> <span class="pre">encoder</span> <span class="pre">(USE)</span></code> model to measure the similarity between two paraphrased sentences and the original sentence. The <code class="docutils literal notranslate"><span class="pre">USE</span></code> will be executed on <code class="docutils literal notranslate"><span class="pre">use_gpu</span></code>. You should change the argument to a proper GPU id.</p></li>
<li><p>We will use a <code class="docutils literal notranslate"><span class="pre">BERT</span></code> model to predict the classification label for paraphrases. The <code class="docutils literal notranslate"><span class="pre">BERT</span></code> will be executed on <code class="docutils literal notranslate"><span class="pre">bert_gpu</span></code>. You should change the argument to a proper GPU id. <strong>Note that the BERT classifier will be trained for the first time you execute the pipeline. Then the trained model will be saved at ``~/.fibber/bert_clf/&lt;dataset_name&gt;/``. Because of the training, it will use more GPU memory than GPT2 and USE. So assign BERT to a separate GPU if you have multiple GPUs.</strong></p></li>
</ul>
<p>After the execution, the evaluation metric for each of the paraphrases will be stored at <code class="docutils literal notranslate"><span class="pre">exp-ag/ag-RandomStrategy-&lt;date&gt;-&lt;time&gt;-with-metrics.json</span></code>.</p>
<p>The aggregated result will be stored as a row at <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/detailed.csv</span></code>.</p>
<p><strong>(4) Generate overview result.</strong></p>
<p>We use the number of wins to compare different strategies. To generate the overview table, use the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m fibber.benchmark.make_overview
</pre></div>
</div>
<p>The overview table will be stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/overview.csv</span></code>.</p>
<p>Before running this command, please verify <code class="docutils literal notranslate"><span class="pre">~/.fibber/results/detailed.csv</span></code>. Each strategy must not have more than one executions on one dataset. Otherwise, the script will raise assertion errors.</p>
</div>
<div class="section" id="id3">
<h2>Datasets<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Here is the information about datasets in fibber.</p>
<table class="table">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Type</p></th>
<th class="head"><p>Name</p></th>
<th class="head"><p>Size (train/test)</p></th>
<th class="head"><p>Classes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Topic Classification</p></td>
<td><p><a class="reference external" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html">ag</a></p></td>
<td><p>120k / 7.6k</p></td>
<td><p>World / Sport / Business / Sci-Tech</p></td>
</tr>
<tr class="row-odd"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="http://www.cs.cornell.edu/people/pabo/movie-review-data/">mr</a></p></td>
<td><p>9k / 1k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-even"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="https://academictorrents.com/details/66ab083bda0c508de6c641baabb1ec17f72dc480">yelp</a></p></td>
<td><p>160k / 38k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-odd"><td><p>Sentiment classification</p></td>
<td><p><a class="reference external" href="https://ai.stanford.edu/~amaas/data/sentiment/">imdb</a></p></td>
<td><p>25k / 25k</p></td>
<td><p>Negative / Positive</p></td>
</tr>
<tr class="row-even"><td><p>Natural Language Inference</p></td>
<td><p><a class="reference external" href="https://nlp.stanford.edu/projects/snli/">snli</a></p></td>
<td><p>570k / 10k</p></td>
<td><p>Entailment / Neutral / Contradict</p></td>
</tr>
<tr class="row-odd"><td><p>Natural Language Inference</p></td>
<td><p><a class="reference external" href="https://cims.nyu.edu/~sbowman/multinli/">mnli</a></p></td>
<td><p>433k / 10k</p></td>
<td><p>Entailment / Neutral / Contradict</p></td>
</tr>
</tbody>
</table>
<p>Note that mnli has two configurations. Use <code class="docutils literal notranslate"><span class="pre">mnli</span></code> for matched testset, and <code class="docutils literal notranslate"><span class="pre">mnli_mis</span></code> for mismatched testset.</p>
<div class="section" id="dataset-format">
<h3>Dataset format<a class="headerlink" href="#dataset-format" title="Permalink to this headline">¶</a></h3>
<p>Each dataset is stored in multiple JSON files. For example, the ag dataset is stored in <code class="docutils literal notranslate"><span class="pre">train.json</span></code> and <code class="docutils literal notranslate"><span class="pre">test.json</span></code>.</p>
<p>The JSON file contains the following fields:</p>
<ul class="simple">
<li><p>label_mapping: a list of strings. The label_mapping maps an integer label to the actual meaning of that label. This list is not used in the algorithm.</p></li>
<li><p>cased: a bool value indicates if it is a cased dataset or uncased dataset. Sentences in uncased datasets are all in lowercase.
paraphrase_field: choose from text0 and text1. Paraphrase_field indicates which sentence in each data record should be paraphrased.</p></li>
<li><p>data: a list of data records. Each data records contains:</p>
<ul>
<li><p>label: an integer indicating the classification label of the text.</p></li>
<li><p>text0:</p>
<ul>
<li><p>For topic and sentiment classification datasets, text0 stores the text to be classified.</p></li>
<li><p>For natural language inference datasets, text0 stores the premise.</p></li>
</ul>
</li>
<li><p>text1:</p>
<ul>
<li><p>For topic and sentiment classification datasets, this field is omitted.</p></li>
<li><p>For natural language inference datasets, text1 stores the hypothesis.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span>
    <span class="p">},</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Apple releases its latest cell phone.&quot;</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="download-datasets">
<h3>Download datasets<a class="headerlink" href="#download-datasets" title="Permalink to this headline">¶</a></h3>
<p>We have scripts to help you easily download all datasets. We provide two options to download datasets:</p>
<ul>
<li><p><strong>Download data preprocessed by us.</strong> We preprocessed datasets and uploaded them to AWS. You can use the following command to download all datasets.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">fibber</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">download_datasets</span>
</pre></div>
</div>
<p>After executing the command, the dataset is stored at <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/&lt;dataset_name&gt;/*.json</span></code>. For example, the ag dataset is stored in <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/ag/</span></code>. And there will be two sets <code class="docutils literal notranslate"><span class="pre">train.json</span></code> and <code class="docutils literal notranslate"><span class="pre">test.json</span></code> in the folder.</p>
</li>
<li><p><strong>Download and process data from the original source.</strong> You can also download the original dataset version and process it locally.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">fibber</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">download_datasets</span> <span class="o">--</span><span class="n">process_raw</span> <span class="mi">1</span>
</pre></div>
</div>
<p>This script will download data from the original source to <code class="docutils literal notranslate"><span class="pre">~/.fibber/datasets/&lt;dataset_name&gt;/raw/</span></code> folder. And process the raw data to generate the JSON files.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="benchmark-result">
<h2>Benchmark result<a class="headerlink" href="#benchmark-result" title="Permalink to this headline">¶</a></h2>
<p>The following table shows the benchmarking result. (Here we show the number of wins.)</p>
<table class="table">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>1_paraphrase_strategy_name</p></th>
<th class="head"><p>USESemanticSimilarity_mean</p></th>
<th class="head"><p>GPT2GrammarQuality_mean</p></th>
<th class="head"><p>3_ParaphraseAcc_usesim0.90_ppl2</p></th>
<th class="head"><p>4_ParaphraseAcc_usesim0.85_ppl5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>IdentityStrategy</p></td>
<td><p>7</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>RandomStrategy</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
</tr>
</tbody>
</table>
<p>For detailed tables, see <a class="reference external" href="https://docs.google.com/spreadsheets/d/1B_5RiMfndNVhxZLX5ykMqt5SCjpy3MxOovBi_RL41Fw/edit?usp=sharing">Google Sheet</a>.</p>
</div>
<div class="section" id="output-format">
<h2>Output format<a class="headerlink" href="#output-format" title="Permalink to this headline">¶</a></h2>
<p>During the benchmark process, we save results in several files.</p>
<div class="section" id="intermediate-result">
<h3>Intermediate result<a class="headerlink" href="#intermediate-result" title="Permalink to this headline">¶</a></h3>
<p>The intermediate result <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/&lt;dataset&gt;-&lt;strategy&gt;-&lt;date&gt;-&lt;time&gt;-tmp.json</span></code> stores the paraphrased sentences. Strategies can run for a few minutes (hours) on some datasets, so we save the result every 30 seconds. The file format is similar to the dataset file. For each data record, we add a new field, <code class="docutils literal notranslate"><span class="pre">text0_paraphrases</span></code> or <code class="docutils literal notranslate"><span class="pre">text1_paraphrases</span></code> depending o the <code class="docutils literal notranslate"><span class="pre">paraphrase_field</span></code>.</p>
<p>An example is as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span><span class="p">,</span>
      <span class="s2">&quot;text0_paraphrases&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="result-with-metrics">
<h3>Result with metrics<a class="headerlink" href="#result-with-metrics" title="Permalink to this headline">¶</a></h3>
<p>The result <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/&lt;dataset&gt;-&lt;strategy&gt;-&lt;date&gt;-&lt;time&gt;-with-metrics.json</span></code> stores the paraphrased sentences as well as metrics. Compute metrics may need a few minutes on some datasets, so we save the result every 30 seconds. The file format is similar to the intermediate file. For each data record, we add two new field, <code class="docutils literal notranslate"><span class="pre">original_text_metrics</span></code> and <code class="docutils literal notranslate"><span class="pre">paraphrase_metrics</span></code>.</p>
<p>An example is as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;label_mapping&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="s2">&quot;World&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sports&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Business&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Sci/Tech&quot;</span>
  <span class="p">],</span>
  <span class="s2">&quot;cased&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
  <span class="s2">&quot;paraphrase_field&quot;</span><span class="p">:</span> <span class="s2">&quot;text0&quot;</span><span class="p">,</span>
  <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
      <span class="s2">&quot;text0&quot;</span><span class="p">:</span> <span class="s2">&quot;Boston won the NBA championship in 2008.&quot;</span><span class="p">,</span>
      <span class="s2">&quot;text0_paraphrases&quot;</span><span class="p">:</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
      <span class="s2">&quot;original_text_metrics&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;EditingDistance&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;USESemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;GloVeSemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;GPT2GrammarQuality&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;BertClfPrediction&quot;</span><span class="p">:</span> <span class="mi">1</span>
      <span class="p">},</span>
      <span class="s2">&quot;paraphrase_metrics&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s2">&quot;EditingDistance&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
          <span class="s2">&quot;USESemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">0.91</span><span class="p">,</span>
          <span class="s2">&quot;GloVeSemanticSimilarity&quot;</span><span class="p">:</span> <span class="mf">0.94</span><span class="p">,</span>
          <span class="s2">&quot;GPT2GrammarQuality&quot;</span><span class="p">:</span> <span class="mf">2.3</span><span class="p">,</span>
          <span class="s2">&quot;BertClfPrediction&quot;</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">},</span>
        <span class="o">...</span>
      <span class="p">]</span>
    <span class="p">},</span>
    <span class="o">...</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">original_text_metrics</span></code> stores a dict of several metrics. It compares the original text against itself. The <code class="docutils literal notranslate"><span class="pre">paraphrase_metrics</span></code> is a list of the same length as paraphrases in this data record. Each element in this list is a dict showing the comparison between the original text and one paraphrased text.</p>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="readme.html" title="previous page">Fibber</a>
    <a class='right-next' id="next-link" href="api/fibber.html" title="next page">fibber package</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020, MIT Data To AI Lab.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>